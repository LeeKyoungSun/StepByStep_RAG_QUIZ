# SCSC/scenario/service.py
from __future__ import annotations

from dataclasses import dataclass
from typing import List, Dict, Any, Optional
from collections import Counter, deque
from pathlib import Path
import json, random, re, os, time, inspect

from openai import OpenAI

from utils.prompts import SCENARIO_PROMPT, USER_TMPL
from scenarios.keyword_rules import match_keywords

from utils.faiss_store import FaissStore
from utils.bm25_store import BM25Store


# -------------------------------
# OpenAI í˜¸ì¶œ í—¬í¼ (SDK ë²„ì „ ì•ˆì „)
# -------------------------------
def _supports_response_format(client) -> bool:
    try:
        sig = inspect.signature(client.responses.create)
        return "response_format" in sig.parameters
    except Exception:
        return False


def call_llm_json(client: OpenAI, prompt: str, model: str, temperature: float = 0.0) -> str:
    """
    ê°€ëŠ¥í•œ ê²½ìš° responses + response_format ì‚¬ìš©,
    ì•„ë‹ˆë©´ responses, ë§ˆì§€ë§‰ í´ë°±ìœ¼ë¡œ chat.completions ì‚¬ìš©.
    í•­ìƒ 'JSON ë¬¸ìì—´'ì„ ë°˜í™˜.
    """
    # 1) responses + response_format
    try:
        if hasattr(client, "responses") and _supports_response_format(client):
            r = client.responses.create(
                model=model,
                input=prompt,
                temperature=temperature,
                response_format={"type": "json_object"},
            )
            return getattr(r, "output_text", None) or r.output[0].content[0].text.value

        # 2) responses (response_format ë¯¸ì§€ì›)
        if hasattr(client, "responses"):
            r = client.responses.create(
                model=model,
                input=prompt,
                temperature=temperature,
            )
            return getattr(r, "output_text", None) or r.output[0].content[0].text.value
    except TypeError:
        pass
    except Exception:
        pass

    # 3) chat.completions í´ë°±
    r = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "Return only valid JSON. No extra text."},
            {"role": "user", "content": prompt},
        ],
        temperature=temperature,
    )
    return r.choices[0].message.content or "{}"


# -------------------------------
# ê°œë… í† í”½ í’€
# -------------------------------
CONCEPT_MAP: Dict[str, List[str]] = {
    "ì„±ë³‘": [
        "HPV ì •ì˜", "HPV ìœ í˜•", "HPV ë°±ì‹ ",
        "í—¤ë¥´í˜ìŠ¤ íŠ¹ì§•", "í—¤ë¥´í˜ìŠ¤ ì¦ìƒ", "í—¤ë¥´í˜ìŠ¤ ì¬ë°œ",
        "í´ë¼ë¯¸ë””ì•„ ì¦ìƒ", "í´ë¼ë¯¸ë””ì•„ ë¬´ì¦ìƒ ê°€ëŠ¥ì„±",
        "ì„ì§ˆ ì¦ìƒ",
        "ë§¤ë… 1ê¸° íŠ¹ì§•", "ë§¤ë… 2ê¸° íŠ¹ì§•", "ë§¤ë… 3ê¸° íŠ¹ì§•",
        "HIV ì „íŒŒ", "HIV ê²€ì‚¬", "HIV ì¹˜ë£Œ",
        "Bí˜•ê°„ì—¼ ì „íŒŒ", "Bí˜•ê°„ì—¼ ì˜ˆë°©ì ‘ì¢…",
        "íŠ¸ë¦¬ì½”ëª¨ë‚˜ìŠ¤ íŠ¹ì§•", "íŠ¸ë¦¬ì½”ëª¨ë‚˜ìŠ¤ ì¹˜ë£Œ",
        "ë¬´ì¦ìƒ ê°€ëŠ¥ì„±", "ì ë³µê¸° ê°œë…", "ê²€ì‚¬ ê¶Œì¥ ì‹œì ",
        "ì„±ë³‘ ê°ì—¼ ê²½ë¡œ", "ì„±ë³‘ ì „íŒŒ ë°©ì‹",
        "ì„±ë³‘ ê²€ì‚¬ ë°©ë²•", "ì„±ë³‘ ê²€ì‚¬ ì£¼ê¸°",
        "ìê°€í‚¤íŠ¸ í™œìš©", "ìµëª…ê²€ì‚¬ í™œìš©",
        "íŒŒíŠ¸ë„ˆ í†µë³´", "ë™ì‹œ ì¹˜ë£Œ", "ì¬ê°ì—¼ ê°€ëŠ¥ì„±", "ì¹˜ë£Œ ì™„ë£Œ ê¸°ì¤€",
        "ì½˜ë”ì˜ ì„±ë³‘ ì˜ˆë°© íš¨ê³¼",
        "êµ¬ê°• ì„±êµ ì˜ˆë°©(ë´íƒˆëŒ)", "í•­ë¬¸ ì„±êµ ì˜ˆë°©(ì½˜ë”)",
        "ë°±ì‹ ìœ¼ë¡œ ì˜ˆë°© ê°€ëŠ¥í•œ ê°ì—¼",
        "ëª©ìš•íƒ• ì „íŒŒ ì˜¤í•´", "í™”ì¥ì‹¤ ì¢Œë³€ê¸° ì „íŒŒ ì˜¤í•´",
        "í‚¤ìŠ¤ë§Œìœ¼ë¡œ ì „íŒŒ ì˜¤í•´", "í•­ìƒì œ ë‚¨ìš© ìœ„í—˜", "í•­ìƒì œ ë‚´ì„± ìœ„í—˜",
    ],
    "í”¼ì„": [
        "ì½˜ë” ê°œë´‰", "ì½˜ë” ê¼­ì§€ ê³µê¸° ë¹¼ê¸°", "ì½˜ë” ì°©ìš© ìˆœì„œ", "ì½˜ë” íƒˆì°©",
        "ì½˜ë” ë³´ê´€ë²•", "ì½˜ë” íŒŒì† ì›ì¸",
        "ì§ˆì™¸ì‚¬ì • ì‹¤íŒ¨ìœ¨", "ì§ˆì™¸ì‚¬ì • ì „ë¶„ë¹„ì•¡ ìœ„í—˜",
        "ì‚¬í›„í”¼ì„ì•½ ë³µìš© ì‹œì ", "ì‚¬í›„í”¼ì„ì•½ íš¨ê³¼", "ì‚¬í›„í”¼ì„ì•½ ë¶€ì‘ìš©",
        "ê²½êµ¬í”¼ì„ì•½ ë³µìš©ë²•", "ê²½êµ¬í”¼ì„ì•½ ë³µìš© ëˆ„ë½ ëŒ€ì²˜", "ê²½êµ¬í”¼ì„ì•½ ë¶€ì‘ìš©",
        "IUD êµ¬ë¦¬ ì¥ë‹¨ì ", "IUD í˜¸ë¥´ëª¬ ì¥ë‹¨ì ", "IUD ë¶€ì‘ìš©",
        "í”¼ì„ íŒ¨ì¹˜ ì‘ìš©", "í”¼ì„ íŒ¨ì¹˜ ëŒ€ìƒ",
        "í”¼ì„ ì£¼ì‚¬ ì‘ìš©", "í”¼ì„ ì£¼ì‚¬ ëŒ€ìƒ",
        "í”¼ì„ ì„í”Œë€íŠ¸ ì‘ìš©", "í”¼ì„ ì„í”Œë€íŠ¸ ëŒ€ìƒ",
        "ì§ˆì • ì‚¬ìš©ë²•", "ì§ˆì • ì‹¤íŒ¨ìœ¨",
        "ë‹¤ì´ì–´í”„ë¨ ì‚¬ìš©ë²•", "ë‹¤ì´ì–´í”„ë¨ ì‹¤íŒ¨ìœ¨",
        "í”¼ì„ ì‹¤íŒ¨ ì‹œ ì‘ê¸‰í”¼ì„", "í”¼ì„ ì‹¤íŒ¨ ì‹œ ì„ì‹  ê°€ëŠ¥ì„± í‰ê°€", "í”¼ì„ ì‹¤íŒ¨ ìƒë‹´",
        "í”¼ì„ê³¼ ì„±ë³‘ ì˜ˆë°©ì˜ ì°¨ì´", "ì´ì¤‘ ë³´í˜¸", "í”¼ì„ ì˜ì‚¬ì†Œí†µ ì „ëµ",
    ],
    "ìƒë¦¬": [
        "ì›”ê²½ ì£¼ê¸°", "ë°°ë€", "ê°œì¸ì°¨ ì›ì¸", "ë¶ˆê·œì¹™ ì›ì¸",
        "ê°€ì„ê¸° ê³„ì‚° í•œê³„", "ê°€ì„ê¸° ê³„ì‚° ì˜¤í•´",
        "ì›”ê²½í†µ ìê¸°ê´€ë¦¬", "ì›”ê²½í†µ ì•½ë¬¼", "ì›”ê²½í†µ ê²½ê³  ì‹ í˜¸",
        "PMS íŠ¹ì§•", "PMDD íŠ¹ì§•", "PMS/PMDD ëŒ€ì²˜",
        "ìƒë¦¬ëŒ€ ì‚¬ìš©", "íƒí° ì‚¬ìš©", "ìƒë¦¬ì»µ ì‚¬ìš©",
        "êµì²´ ì£¼ê¸°", "ìœ„ìƒ ê´€ë¦¬",
        "ìŠ¤íŒŸíŒ… ì›ì¸", "ì£¼ê¸° ë³€í™” ì›ì¸", "ìŠ¤íŠ¸ë ˆìŠ¤ ì˜í–¥", "ì²´ì¤‘ ë³€í™” ì˜í–¥", "ì•½ë¬¼ ì˜í–¥",
        "ì´ˆê²½ ì•ˆë‚´", "ì‚¬ì¶˜ê¸° ë³€í™”",
        "ìˆ˜ì˜ ì‹œ ìš©í’ˆ ì„ íƒ", "ì²´ìœ¡ ì‹œ ìš©í’ˆ ì„ íƒ",
        "ê³¼ë‹¤ ì›”ê²½ ìƒë‹´ ê¸°ì¤€", "ê³¼ì†Œ ì›”ê²½ ìƒë‹´ ê¸°ì¤€",
    ],
    "ê²½ê³„/ë™ì˜": [
        "ë™ì˜ ì›ì¹™: ììœ ", "ë™ì˜ ì›ì¹™: ëª…í™•ì„±", "ë™ì˜ ì›ì¹™: êµ¬ì²´ì„±", "ë™ì˜ ì›ì¹™: ê°€ì—­ì„±",
        "ì·¨ì¤‘ ë™ì˜ ë¬´íš¨", "ì••ë°• ê´€ê³„ ë™ì˜ ë¬´íš¨", "ê¶Œë ¥ê´€ê³„ ë™ì˜ ë¬´íš¨",
        "ê²½ê³„ ì„¤ì • ë°©ë²•", "ì˜ì‚¬í‘œí˜„ ë¬¸ì¥ ì˜ˆì‹œ",
        "ê±°ì ˆ ë’¤ ëŒ€í™”", "ê´€ê³„ ì¡´ì¤‘",
        "ë””ì§€í„¸ ë™ì˜: ì‚¬ì§„ ì´¬ì˜", "ë””ì§€í„¸ ë™ì˜: ì˜ìƒ ê³µìœ ",
        "ë™ì˜ì˜ ì§€ì†ì„±", "ë™ì˜ì˜ ì² íšŒ",
    ],
    "ê´€ê³„/ì˜ì‚¬ì†Œí†µ": [
        "ê°ì • ì¸ì‹", "ê°ì • í‘œí˜„", "ê²½ì²­ ìŠ¤í‚¬",
        "ë‚˜-ë©”ì‹œì§€", "ë¹„ë‚œ ëŒ€ì‹  êµ¬ì²´ì  ìš”ì²­",
        "ê°ˆë“± í•´ê²°: ì‚¬ì‹¤/ê°ì •/ìš”ì²­ ë¶„ë¦¬",
        "ì—°ì•  ì˜ì‚¬ê²°ì •", "ì—°ì•  ìƒí˜¸ ì¡´ì¤‘",
        "ê°œì¸ì •ë³´ ê³µìœ  ë²”ìœ„", "ë¹„ë°€ë³´ì¥",
        "ì§ˆë¬¸ ìŠ¤í‚¬", "í™•ì¸ ìŠ¤í‚¬", "í™•ì¦ í¸í–¥ ì¤„ì´ê¸°",
    ],
    "ì˜¨ë¼ì¸/ë””ì§€í„¸": [
        "ë””ì§€í„¸ ì„±ë²”ì£„: ë¶ˆë²•ì´¬ì˜/ìœ í¬/í˜‘ë°•",
        "ì‚¬ì§„ ìš”êµ¬ ê±°ì ˆ ë¬¸ì¥", "ì°¨ë‹¨", "ì¦ê±° ë³´ì¡´",
        "ì‹ ê³  112", "ìƒë‹´ 1366", "ë””ì§€í„¸ ì„±ë²”ì£„ ì§€ì›ë‹¨",
        "2ë‹¨ê³„ ì¸ì¦", "ë¹„ë°€ë²ˆí˜¸ ê´€ë¦¬",
        "ì €ì‘ê¶Œ/ì´ˆìƒê¶Œ ê¸°ë³¸", "ìœ í•´ë¬¼ ì‹ ê³ ",
    ],
    "ì„ì‹ /ì¶œì‚°": [
        "ì„ì‹  ê°€ëŠ¥ì„±", "ê°€ì„ê¸° ì˜¤í•´ ë°”ë¡œì¡ê¸°",
        "ì„ì‹  í…ŒìŠ¤íŠ¸ê¸° ì‹œì /íŒë…",
        "ì„ì‹  ì´ˆê¸° ì¦ìƒ/í™•ì¸ ì ˆì°¨",
        "ì„ì‹ ì¤‘ì ˆ ì •ë³´ ì ‘ê·¼/ìƒë‹´",
        "ì˜ë£Œê¸°ê´€ ì°¾ê¸°/ë¹„ë°€ë³´ì¥", "ì„ì‹  ì•ˆì „",
    ],
    "ê±´ê°•/ìƒë‹´": [
        "í•™êµ ë³´ê±´ì‹¤/ë³´ê±´êµì‚¬ í™œìš©",
        "ì²­ì†Œë…„ ì¹œí™” ì˜ë£Œê¸°ê´€ ì°¾ê¸°",
        "ë¹„ë°€ë³´ì¥/ë™ë°˜ì ë™ì˜",
        "ë¶ˆì•ˆ/ìš°ìš¸/ì •ì‹ ê±´ê°•ê³¼ ì„±",
        "í—¬í”„ë¼ì¸ 112/1366/ìœ„ê¸°ëŒ€ì‘",
        "ìƒë‹´ ì¤€ë¹„: ì¦ìƒ ê¸°ë¡/ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸",
    ],
    "ì‹ ì²´ ë³€í™”": [
        "ì‚¬ì¶˜ê¸° 2ì°¨ ì„±ì§•/ê°œì¸ì°¨",
        "ìŒê²½/ê³ í™˜/í¬ê²½/ëª½ì •/ë°œê¸°",
        "ìœ ë°© ë°œë‹¬/ë¸Œë¼ ì„ íƒ",
        "ì²´ëª¨/ëª©ì†Œë¦¬/í”¼ë¶€ ë³€í™” ê´€ë¦¬",
        "ì‹ ì²´ ì´ë¯¸ì§€/ìê¸°ì¡´ì¤‘ê°",
    ],
    "ì™¸ëª¨/ìê¸°ì´ë¯¸ì§€": [
        "ì²´ì¤‘/ì²´í˜•ê³¼ ê±´ê°•",
        "ë‹¤ì´ì–´íŠ¸ ì˜¤í•´", "ì—¬ë“œë¦„/í”¼ë¶€ ê´€ë¦¬",
        "ë¯¸ë””ì–´ ë³´ì •/í•„í„° ì¸ì‹", "ì™¸ëª¨ ê´´ë¡­í˜ ëŒ€ì²˜",
    ],
    "ììœ„/ìš•êµ¬": [
        "ì„±ì  ìš•êµ¬/ììœ„ì˜ ì •ìƒì„±",
        "ì˜¤í•´ êµì •", "í”„ë¼ì´ë²„ì‹œ/ìœ„ìƒ/ë””ì§€í„¸ ì•ˆì „",
        "ì½˜í…ì¸  ì„ íƒ/ê²½ê³„ ì„¤ì •",
    ],
}

SCENARIO_BACKGROUNDS = [
    "ìˆ˜ì—… ëë‚˜ê³  ë³µë„ì—ì„œ ëŒ€í™” ì¤‘", "ë™ì•„ë¦¬ í™œë™ ì‰¬ëŠ” ì‹œê°„", "ë‹¨ì²´ ì±„íŒ…ì—ì„œ ì˜ê²¬ì„ ë‚˜ëˆ„ëŠ” ì¤‘",
    "ê³µì› ë²¤ì¹˜ì—ì„œ ì´ì•¼ê¸°í•˜ëŠ” ì¤‘", "ë³´ê±´ì‹¤ ìƒë‹´ ëŒ€ê¸° ì¤‘", "ì˜¨ë¼ì¸ ë©”ì‹ ì € ëŒ€í™” ì¤‘",
    "ê¸‰ì‹ ì¤„ì—ì„œ ì¡ë‹´ ì¤‘", "ì¡°ë³„ ê³¼ì œ íšŒì˜ ì¤‘", "ë“±êµ£ê¸¸ ë²„ìŠ¤ ì•ˆ", "ë„ì„œê´€ ììŠµ ì¤‘",
    "ì²´ìœ¡ ì‹œê°„ íŒ€ í™œë™ ì „", "í•™ê¸‰ ê²Œì‹œíŒ ì•", "í•™êµ ì¶•ì œ ì¤€ë¹„ ì¤‘",
    "ì²­ì†Œë…„ìƒë‹´ë³µì§€ì„¼í„° ëŒ€ê¸°ì‹¤", "ë³´ê±´ì†Œ ì˜ˆì•½ ì „í™” ì „", "ì£¼ë§ ìŠ¤í„°ë”” ì¹´í˜",
]

SCENARIO_ENDINGS = [
    "ë„ˆë¼ë©´ ì–´ë–»ê²Œ í• ë˜?", "ì§€ê¸ˆ ì„ íƒí•  í–‰ë™ì€ ë¬´ì—‡ì¼ê¹Œ?", "ì–´ë–¤ ë§ë¶€í„° êº¼ë‚¼ë˜?",
    "ë¨¼ì € í™•ì¸í•´ì•¼ í•  ê²ƒì€ ë¬´ì—‡ì¼ê¹Œ?", "ëˆ„êµ¬ì™€ ìƒì˜í•´ë³¼ê¹Œ?", "ê°€ì¥ ì•ˆì „í•œ ì„ íƒì€ ë¬´ì—‡ì¼ê¹Œ?",
    "ë„¤ê°€ ì·¨í•  ìˆ˜ ìˆëŠ” ë‹¤ìŒ í•œ ê±¸ìŒì€?", "ìƒëŒ€ë¥¼ ì¡´ì¤‘í•˜ë©´ì„œ ë­ë¼ê³  ë§í•˜ê² ì–´?",
]

CONCEPT_FORMS = [
    "{topic}ëŠ” ë¬´ì—‡ì¼ê¹Œ?",
    "ë‹¤ìŒ ì¤‘ {topic}ì˜ íŠ¹ì§•ìœ¼ë¡œ ì˜³ì€ ê²ƒì€?",
    "{topic}ì— ëŒ€í•œ ì„¤ëª…ìœ¼ë¡œ ë§ëŠ” ê²ƒì„ ê³¨ë¼.",
    "{topic} ì˜ˆë°© ë˜ëŠ” ê´€ë¦¬ ë°©ë²•ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ê²ƒì€?",
]

RECENT_MAX = 20


@dataclass
class Config:
    index_root: str = "SCSC/indexes"  # window/ qna ë£¨íŠ¸ ìƒìœ„
    topk: int = 6
    max_context_chars: int = 1600
    gen_model: str = "gpt-4o-mini"


class ScenarioService:
    def __init__(self, cfg: Config):
        self.cfg = cfg
        self.faiss = self._try_load_faiss()
        self.bm25 = self._try_load_bm25()
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self._pool = self._load_pool()
        self._keywords = None
        self._recent_questions = deque(maxlen=RECENT_MAX)
        self._topic_cycle: Dict[str, List[str]] = {}

    # ---------- ìƒíƒœ ìœ í‹¸ ----------
    def _mk_facts(self, snips: List[Dict[str, Any]], max_chars: int = 900) -> str:
        """ìŠ¤ë‹ˆí«ì„ ì‹œí—˜ìš© FACTSë¡œ ì••ì¶•."""
        facts, used = [], 0
        for s in snips:
            t = (s.get("text") or "").strip()
            if not t:
                continue
            # ë¬¸ì¥ 1~2ê°œë§Œ ì¶”ì¶œ
            for one in re.split(r"[.!?]\s+", t)[:2]:
                one = " ".join(one.split())
                if len(one) < 12:
                    continue
                if used + len(one) + 3 > max_chars:
                    return "\n".join(f"- {f}" for f in facts)
                facts.append(one)
                used += len(one) + 3
        return "\n".join(f"- {f}" for f in facts) if facts else ""

    @staticmethod
    def _unify_register(text: str) -> str:
        if not isinstance(text, str):
            return text
        t = re.sub(r"ìš”[.!?]?$", "", text)
        t = (t.replace("ì‹­ì‹œì˜¤", "ìš”")
               .replace("í•˜ì„¸ìš”", "í•´")
               .replace("í•´ì£¼ì„¸ìš”", "í•´ì¤˜"))
        return re.sub(r"\s+", " ", t).strip()

    @staticmethod
    def _too_similar(a: str, b: str, th: float = 0.7) -> bool:
        ta = set(a.replace(",", " ").replace(".", " ").split())
        tb = set(b.replace(",", " ").replace(".", " ").split())
        if not ta or not tb:
            return False
        j = len(ta & tb) / max(1, len(ta | tb))
        return j >= th

    def _push_recent(self, q: str) -> bool:
        for prev in self._recent_questions:
            if self._too_similar(prev, q):
                return False
        self._recent_questions.append(q)
        return True

    def _next_concept_topic(self, kw: str) -> Optional[str]:
        pool = CONCEPT_MAP.get(kw or "", [])
        if not pool:
            return None
        if kw not in self._topic_cycle or not self._topic_cycle[kw]:
            arr = pool[:]
            random.shuffle(arr)
            self._topic_cycle[kw] = arr
        return self._topic_cycle[kw].pop()

    def _scenario_hint(self) -> str:
        bg = random.choice(SCENARIO_BACKGROUNDS)
        end = random.choice(SCENARIO_ENDINGS)
        return f"[ë°°ê²½] {bg}\n[ë§ˆë¬´ë¦¬ ì§ˆë¬¸] {end}"

    # ---------- ë””ë²„ê·¸ìš©: ê·¼ê±° ë³´ê¸° ----------
    def show_sources(self, item: Dict[str, Any]) -> str:
        def _src_key(d: Dict[str, Any]) -> str:
            return d.get("source") or d.get("src") or d.get("source_path") or d.get("doc") or ""

        def _cid(v: Any) -> str:
            return str(v) if v is not None else ""

        out = []
        refs = item.get("sources", []) if isinstance(item, dict) else []
        if not refs:
            return "(ê·¼ê±° ì—†ìŒ)"

        want = {(_src_key(r), _cid(r.get("chunk_id"))) for r in refs}

        for s in self._pool:
            got_src = _src_key(s)
            got_cid = _cid(s.get("chunk_id"))
            if (got_src, got_cid) in want:
                out.append(f"[{got_src} #{got_cid}] {s.get('text', '')}")
        return "\n".join(out) if out else "(ê·¼ê±° ì—†ìŒ)"

    # ---------- ì¸ë±ìŠ¤ ë¡œë“œ ----------
    def _try_load_faiss(self):
        root = Path(self.cfg.index_root)
        candidates = list(root.glob("**/*_mac")) + list(root.glob("**/*_window"))
        for d in candidates:
            try:
                return FaissStore.load(str(d))
            except Exception:
                continue
        return None

    def _try_load_bm25(self):
        root = Path(self.cfg.index_root)
        candidates = list(root.glob("**/*_mac")) + list(root.glob("**/*_window"))
        for d in candidates:
            try:
                return BM25Store.load(str(d))
            except Exception:
                continue
        return None

    def _load_pool(self) -> List[Dict[str, Any]]:
        """ì¸ë±ìŠ¤ì—ì„œ ì „ì²´ ìŠ¤ë‹ˆí« í’€ 1íšŒ êµ¬ì¶•"""
        pool: List[Dict[str, Any]] = []
        for p in Path(self.cfg.index_root).glob("**/meta.json"):
            arr = json.loads(p.read_text(encoding="utf-8"))
            for row in arr:
                txt = row.get("text") or row.get("chunk_text") or ""
                if not txt:
                    continue
                kws = row.get("keywords") or match_keywords(txt)
                pool.append({
                    "text": " ".join(txt.split()),
                    "source": row.get("src") or row.get("source") or p.parent.name,
                    "chunk_id": row.get("chunk_id"),
                    "keywords": kws,
                })
        return pool

    # ---------- ê²€ìƒ‰ ----------
    def search(self, query: str, topk: int) -> List[Dict[str, Any]]:
        results: List[Dict[str, Any]] = []
        if self.faiss:
            results += self.faiss.search(query, top_k=topk)
        if self.bm25:
            results += self.bm25.search(query, top_k=topk)
        if not results:
            return []
        # ê°„ë‹¨ RRF
        def k(s): return f"{s.get('source')}#{s.get('chunk_id')}"
        scored: Dict[str, float] = {}
        for rank, s in enumerate(results, start=1):
            scored[k(s)] = scored.get(k(s), 0.0) + 1.0 / (60 + rank)
        uniq = {k(s): s for s in results}
        ranked = sorted(uniq.values(), key=lambda s: scored[k(s)], reverse=True)
        return ranked[:topk]

    def random_snippets(self, topk: int) -> List[Dict[str, Any]]:
        if not self._pool:
            return []
        return random.sample(self._pool, k=min(topk, len(self._pool)))

    # ---------- í‚¤ì›Œë“œ ----------
    def keywords(self, limit: int = 40):
        WHITELIST = (
            "í”¼ì„", "ìƒë¦¬", "ì—°ì• ", "ì™¸ëª¨", "ì‹ ì²´ ë³€í™”",
            "ì  ë”", "ê´€ê³„/ì˜ì‚¬ì†Œí†µ", "ê²½ê³„/ë™ì˜", "ì˜¨ë¼ì¸/ë””ì§€í„¸",
            "ì„±ë³‘/ê²€ì‚¬", "ì„ì‹ /ì¶œì‚°", "ììœ„/ìš•êµ¬", "ê±´ê°•/ìƒë‹´",
        )
        c = Counter()
        for s in self._pool:
            for kw in s.get("keywords", ()):
                c[kw] += 1
        ordered = [(k, c[k]) for k in WHITELIST if k in c]
        if not ordered:
            ordered = sorted(c.items(), key=lambda x: x[1], reverse=True)
        return [{"keyword": k, "count": v} for k, v in ordered[:limit]]

    def pick_by_keyword(self, keyword: str, topk: int):
        cand = [s for s in self._pool if keyword in s.get("keywords", [])]
        if not cand:
            return []
        random.shuffle(cand)
        if self.faiss:
            query = f"{keyword} ì›ì¹™ ê°œë… ì˜ˆë°© ê²€ì‚¬ íŠ¹ì§• ì‚¬ë¡€"
            ranked = self.faiss.search(query, top_k=topk * 3)
            allow = {(s["source"], s.get("chunk_id")) for s in cand}
            ranked = [r for r in ranked if (r.get("source"), r.get("chunk_id")) in allow]
            random.shuffle(ranked)
            if ranked:
                return ranked[:topk]
        return cand[:topk]

    # ---------- ë‚´ë¶€ ìœ í‹¸ ----------
    def _concept_snippets(self, keyword: str, topic: str, topk: int) -> List[Dict[str, Any]]:
        def _variants(t: str) -> List[str]:
            t2 = re.sub(r"[\(\)]", " ", t)
            toks = [t, t2]
            if "HPV" in t.upper(): toks += ["HPV", "ì¸ìœ ë‘ì¢…", "ì¸ìœ ë‘ì¢…ë°”ì´ëŸ¬ìŠ¤"]
            if "HIV" in t.upper(): toks += ["HIV", "AIDS", "ì—ì´ì¦ˆ"]
            return list(dict.fromkeys([re.sub(r"\s+", " ", x).strip() for x in toks if x.strip()]))

        pats = [re.compile(re.escape(v), re.IGNORECASE) for v in _variants(topic)]
        hits = []
        for s in self._pool:
            if keyword and keyword not in (s.get("keywords") or []):
                continue
            txt = s.get("text") or ""
            if any(p.search(txt) for p in pats):
                hits.append(s)
                if len(hits) >= topk:
                    break
        if len(hits) >= max(2, topk // 2):
            random.shuffle(hits)
            return hits[:topk]

        q = f"{topic} ì •ì˜ íŠ¹ì§• ì „íŒŒ ê²½ë¡œ ì˜ˆë°© ê²€ì‚¬ ì„¤ëª… ê·¼ê±°"
        found = self.search(q, topk=topk * 2)
        if keyword and found:
            f2 = [r for r in found if keyword in (r.get("keywords") or [])]
            found = f2 or found
        random.shuffle(found)
        return (found or hits or self.random_snippets(topk))[:topk]

    @staticmethod
    def _normalize_choices(choices: List[str]) -> List[str]:
        norm = []
        for c in choices:
            if not isinstance(c, str):
                continue
            cc = re.sub(r"^\s*[A-Da-d]\s*[\.\):]\s*", "", c).strip()
            cc = re.sub(r"\s+", " ", cc)
            if cc:
                norm.append(cc)
        seen, out = set(), []
        for c in norm:
            if c not in seen:
                out.append(c)
                seen.add(c)
        return out

    @staticmethod
    def _looks_bad_choices(choices: List[str]) -> bool:
        if len(choices) != 4:
            return True
        if any(len(c.strip()) < 8 for c in choices):
            return True
        norm = [re.sub(r"\s+", " ", c.strip()) for c in choices]
        if len(set(norm)) < 4:
            return True
        bad_phrases = ["ë¬´ì‹œí•˜ê³ ", "ê°•ì œë¡œ", "ì¦‰ì‹œ ê´€ê³„", "í”¼ì„ ì—†ì´", "ì•„ë¬´ ì¤€ë¹„ ì—†ì´"]
        if sum(any(p in c for p in bad_phrases) for c in norm) >= 3:
            return True
        return False

    @staticmethod
    def _contains_english_name(text: str) -> bool:
        return bool(re.search(r"\b[A-Z][a-z]{2,}\b", text or ""))

    # ---------- ì•„ì´í…œ ìƒì„± ----------
    def _mk_context(self, snips: List[Dict[str, Any]]) -> str:
        buf, cur = [], 0
        for s in snips:
            t = " ".join((s.get("text") or "").split())
            if not t:
                continue
            if cur + len(t) > self.cfg.max_context_chars:
                t = t[: max(0, self.cfg.max_context_chars - cur)]
            buf.append(f"- ({s.get('source','')}, chunk#{s.get('chunk_id')}) {t}")
            cur += len(t)
            if cur >= self.cfg.max_context_chars:
                break
        return "\n".join(buf)

    def make_quiz_item(
        self,
        keyword: Optional[str],
        snips: List[Dict[str, Any]],
        force_type: Optional[str] = None,  # "concept" | "situation" | None
        concept_topic: Optional[str] = None,
    ) -> Dict[str, Any]:
        # 1) ìœ í˜•/ì£¼ì œ
        qtype = force_type or "situation"
        topic = concept_topic or (keyword or "í•µì‹¬ ê°œë…")

        # ğŸ”§ ê°œë…í˜•ì€ ê´€ë ¨ ìŠ¤ë‹ˆí«ì„ ë‹¤ì‹œ ë½‘ì•„ì„œ ì‚¬ìš©(RAG ê°•ì œ)
        if qtype == "concept":
            snips = self._concept_snippets(keyword or "", topic, self.cfg.topk)

        # 2) context/extra_hint (FACTSë§Œ ì‚¬ìš©)
        context = self._mk_facts(snips)
        if qtype == "concept":
            extra_hint = (
                "[ì¶œì œ í˜•íƒœ] type=concept\n"
                f"[ê°œë… ì£¼ì œ] {topic}\n"
                "- ì•„ë˜ FACTSë§Œ ì‚¬ìš©í•´ì„œ ë¬¸ì œì™€ ë³´ê¸°ë¥¼ ë§Œë“¤ì–´.\n"
                "- FACTSì— ì—†ëŠ” ì •ë³´/ìˆ«ì/ê¸°ê´€ëª…/ì£¼ì¥ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆ.\n"
                "- ë³´ê¸° 4ê°œ: ì •í™•í•œ ì •ì˜/íŠ¹ì§•(ì •ë‹µ) + ë¶ˆì™„ì „ + ì˜¤í•´ + ë¬´ê´€.\n"
                "- ì§ˆë¬¸ì€ ì‹œí—˜ë¬¸ì¥ í˜•íƒœë¡œ ëë‚´ê³ , ê¶Œìœ í˜• ì ‘ë¯¸ ê¸ˆì§€.\n"
            )
        else:
            extra_hint = (
                self._scenario_hint() + "\n"
                "[ì¶œì œ í˜•íƒœ] type=situation\n"
                "- ì•„ë˜ FACTSë§Œ ì‚¬ìš©. FACTS ë°–ì˜ ë‚´ìš©/ì¡°ì–¸/ê¸°ê´€ëª… ì¶”ê°€ ê¸ˆì§€.\n"
                "- ë³´ê¸° 4ê°œ: ì •ë‹µ(ê·¼ê±° ê¸°ë°˜ ì•ˆì „í–‰ë™) + ë¶ˆì™„ì „ + ì˜¤í•´ + ë¶€ì ì ˆ.\n"
            )

        # 3) ì´ˆê¸° sources/evidence (ì–‘ìª½ ê³µí†µ: retrieval)
        norm_sources: List[Dict[str, Any]] = []
        for s in snips[:2]:
            src = (s.get("source") or s.get("src") or s.get("source_path") or s.get("doc") or "")
            cid = s.get("chunk_id") or s.get("id") or s.get("uid")
            if src:
                norm_sources.append({"source": src, "chunk_id": cid})
        data: Dict[str, Any] = {"sources": norm_sources, "evidence": "retrieval"}

        # 4) í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
        tone = "ì¹œê·¼ë°˜ë§"
        try:
            from utils.prompts import TONE_PRESETS, USER_TMPL as _USER_TMPL
            user = _USER_TMPL.format(
                qtype=qtype, tone=tone, keyword=keyword or "(ëœë¤)",
                tone_block=TONE_PRESETS.get(tone, ""),
                context=("## FACTS(ë°˜ë“œì‹œ ì´ ì•ˆì—ì„œë§Œ ì‘ì„±)\n" + (context or "(ì—†ìŒ)")),
            ) + "\n" + extra_hint + (
                "\n[ê°•í•œ ì œì•½]\n"
                "- ë°˜ë“œì‹œ FACTS ì•ˆì˜ ì‚¬ì‹¤ë§Œ ì‚¬ìš©í•´.\n"
                "- ìƒˆë¡œìš´ ì¶œì²˜ëª…/ê¸°ê´€ëª…/ìë£Œëª… ì¶”ê°€ ê¸ˆì§€.\n"
                "- ì•„ë¬´ê²ƒë„ í™•ì •í•  ìˆ˜ ì—†ìœ¼ë©´ 'ë¶ˆì™„ì „' ë³´ê¸°ì— ë„£ì–´.\n"
                "- ì¶œë ¥ì€ JSONë§Œ."
            )
        except Exception:
            tone_block = (
                "[ë§íˆ¬ ê°€ì´ë“œ]\n"
                "- ì¹œêµ¬ì—ê²Œ ë§í•˜ë“¯ ë”°ëœ»í•˜ê³  ì¡´ì¤‘í•˜ëŠ” ë°˜ë§.\n"
                "- ë¹„ë‚œ/ì¡°ë¡± ê¸ˆì§€, ì •ë³´ì™€ ê·¼ê±° ì¤‘ì‹¬.\n"
                "- ë¬¸ì¥ ê°„ê²°(1~2ì ˆ), ê¶Œìœ í˜• ì ‘ë¯¸ ê¸ˆì§€.\n"
            )
            user = USER_TMPL.format(keyword=keyword or "(ëœë¤)", context=context) \
                   + "\n" + tone_block + "\n" + extra_hint

        # 5) ëª¨ë¸ í˜¸ì¶œ(ìµœëŒ€ 3íšŒ, ì˜¨ë„ 0.0 ê³ ì •)
        for attempt in range(3):
            try:
                prompt = json.dumps({"system": SCENARIO_PROMPT, "user": user}, ensure_ascii=False)
                text = call_llm_json(
                    client=self.client,
                    prompt=prompt,
                    model=getattr(self.cfg, "gen_model", "gpt-4o-mini"),
                    temperature=0.0,
                )
                data = json.loads(text or "{}")
                break
            except Exception as e:
                print(f"[WARN] Quiz generation attempt {attempt + 1} failed: {e}")
                if attempt == 2:
                    raise
                time.sleep(0.4 * (attempt + 1))

        if not isinstance(data, dict):
            data = {}

        # 6) ì„ íƒì§€ ì •ë¦¬
        choices = data.get("choices", [])
        try:
            choices = self._normalize_choices(choices)
        except Exception:
            norm = []
            for c in (choices or []):
                if not isinstance(c, str):
                    continue
                cc = re.sub(r"^\s*[A-Da-d]\s*[\.\):]\s*", "", c).strip()
                cc = re.sub(r"\s+", " ", cc)
                if cc:
                    norm.append(cc)
            seen, tmp = set(), []
            for c in norm:
                if c not in seen:
                    tmp.append(c); seen.add(c)
            choices = tmp
        while len(choices) < 4:
            choices.append("ì¶”ê°€ ë³´ê¸°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        data["choices"] = choices[:4]

        # 7) ì •ë‹µ/ë¼ì‡¼ë‚ /íƒ€ì… ë³´ì •
        ai = data.get("answer_index")
        if not isinstance(ai, int) or not (0 <= ai < 4):
            data["answer_index"] = 0
        if not data.get("rationale"):
            data["rationale"] = "ì •ë‹µì€ ì •í™•í•œ ì„¤ëª…ì´ê³ , ë‚˜ë¨¸ì§€ëŠ” ë¶ˆì™„ì „Â·ì˜¤í•´Â·ë¬´ê´€í•œ ì„¤ëª…ì´ì•¼."
        data["type"] = qtype

        # 8) ì†ŒìŠ¤(ê·¼ê±°) ë³´ê°•(ì—†ìœ¼ë©´ ì„¸íŒ…)
        if not data.get("sources"):
            data["sources"] = norm_sources
        data["evidence"] = "retrieval"

        # 9) í†¤/í‘œí˜„ ì •ë¦¬
        try:
            data["question"] = self._unify_register(data.get("question", ""))
            data["choices"] = [self._unify_register(c) for c in data["choices"]]
            data["rationale"] = self._unify_register(data.get("rationale", ""))
        except Exception:
            pass

        if data.get("type") == "concept":
            data["question"] = re.sub(
                r"(í•¨ê»˜\s*í™•ì¸í•´ë³´ì|ê°™ì´\s*ì•Œì•„ë³´ì|í•¨ê»˜\s*ì•Œì•„ë³´ì)\s*\.?$", "", data["question"]
            ).strip()

        # 10) FACTSì™€ì˜ ê²¹ì¹¨ ì²´í¬(ë¼ìŠ¤íŠ¸ ê°€ë“œ)
        facts_blob = context or ""
        def _overlap_ok(s: str) -> bool:
            a = set(re.findall(r"[ê°€-í£A-Za-z0-9]+", s))
            b = set(re.findall(r"[ê°€-í£A-Za-z0-9]+", facts_blob))
            if not a or not b:
                return True
            return len(a & b) >= max(2, len(a)//6)

        if not _overlap_ok(data.get("question", "")) or any(not _overlap_ok(c) for c in data["choices"]):
            data["question"] = "ìƒí™©ì„ ì½ê³  FACTSì— ê·¼ê±°í•œ ê°€ì¥ ì•ˆì „í•œ ì„ íƒì„ ê³¨ë¼."
            data["choices"] = [
                "FACTSì— ë‚˜ì˜¨ ì•ˆì „í–‰ë™ì„ ë”°ë¥¸ë‹¤.",
                "FACTSì— ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ì§€ë§Œ ê´œì°®ì•„ ë³´ì´ëŠ” í–‰ë™ì„ í•œë‹¤.",
                "ì£¼ë³€ ë§ë§Œ ë¯¿ê³  FACTSë¥¼ ë¬´ì‹œí•œë‹¤.",
                "ì•„ë¬´ ê·¼ê±° ì—†ì´ ì¦‰í¥ì ìœ¼ë¡œ ê²°ì •í•œë‹¤.",
            ]
            data["answer_index"] = 0

        # 11) ë³´ê¸° ì„ê¸°
        correct_choice = data["choices"][data["answer_index"]]
        random.shuffle(data["choices"])
        data["answer_index"] = data["choices"].index(correct_choice)
        data["answer_letter"] = ["A", "B", "C", "D"][data["answer_index"]]

        return data

    # ---------- ì„¸íŠ¸ ìƒì„± ----------
    def make_quiz(self, mode: str, keyword: Optional[str], n: int = 5):
        out: List[Dict[str, Any]] = []
        for i in range(max(1, n)):
            if mode == "by_keyword" and keyword:
                snips = self.pick_by_keyword(keyword, self.cfg.topk)
                if not snips:
                    expand = {"í”¼ì„": ["ì„±ë³‘/ê²€ì‚¬", "ê²½ê³„/ë™ì˜"],
                              "ìƒë¦¬": ["ì‹ ì²´ ë³€í™”", "ê±´ê°•/ìƒë‹´"],
                              "ì—°ì• ": ["ê´€ê³„/ì˜ì‚¬ì†Œí†µ", "ê²½ê³„/ë™ì˜"]}
                    for k2 in expand.get(keyword, []):
                        snips = self.pick_by_keyword(k2, self.cfg.topk)
                        if snips:
                            break
                if not snips:
                    snips = self.random_snippets(self.cfg.topk)
                kw = keyword
            else:
                snips = self.random_snippets(self.cfg.topk)
                kw = (snips and snips[0].get("keywords") and random.choice(snips[0]["keywords"])) or "ëœë¤"

            force_type = "concept" if (i % 2 == 1) else "situation"
            concept_topic = None
            if force_type == "concept":
                concept_topic = self._next_concept_topic(kw or keyword or "")

            item = self.make_quiz_item(kw, snips, force_type=force_type, concept_topic=concept_topic)
            if isinstance(item, dict) and "choices" in item and "answer_index" in item:
                out.append(item)
        return out


# ---------- íŒ©í† ë¦¬ ----------
def get_service() -> "ScenarioService":
    cfg = Config()
    cfg.index_root = os.getenv("SCENARIO_INDEX_ROOT", cfg.index_root or "SCSC/indexes")
    try:
        cfg.topk = int(os.getenv("SCENARIO_TOPK", str(cfg.topk or 6)))
    except Exception:
        cfg.topk = 6
    cfg.gen_model = os.getenv("GEN_MODEL", cfg.gen_model or "gpt-4o-mini")
    if not hasattr(cfg, "embed_model") or not getattr(cfg, "embed_model", None):
        cfg.embed_model = os.getenv("EMBED_MODEL", "text-embedding-3-small")

    Path(cfg.index_root).mkdir(parents=True, exist_ok=True)
    return ScenarioService(cfg)


# í˜¸í™˜ ì‹¬ë³¼
engine = None
svc = None